{
  "id": "task_201_pipeline",
  "name": "Data Processing Pipeline",
  "description": "Multi-stage data processing with Result-based error handling",
  "tier": "tier3_integration",
  "prompt": "Create a data processing pipeline with proper error handling using Result types.\n\nImplement the following in src/core/pipeline.py:\n\n1. `Result` class (or use returns library) with:\n   - `Success(value)` and `Failure(error)` variants\n   - `map(fn)` - Transform success value\n   - `bind(fn)` - Chain operations that return Result\n   - `unwrap()` - Get value or raise\n   - `unwrap_or(default)` - Get value or default\n\n2. `Pipeline` class with:\n   - `add_stage(name: str, fn: Callable)` - Add processing stage\n   - `run(data: Any) -> Result` - Run all stages, stop on first failure\n   - `run_all(data: Any) -> tuple[Result, list[str]]` - Run all stages, collect all errors\n\n3. Built-in stage functions:\n   - `validate_not_empty(data: str) -> Result` - Fail if empty string\n   - `parse_json(data: str) -> Result` - Parse JSON, fail on invalid\n   - `validate_schema(data: dict, required_fields: list) -> Result` - Check required fields\n   - `transform_keys_to_lower(data: dict) -> Result` - Lowercase all dict keys\n\nEach stage should return Result to enable proper error propagation. Use contracts to ensure pipeline invariants.",
  "initial_files": {},
  "test_file": "import pytest\nimport sys\nsys.path.insert(0, 'src')\nfrom core.pipeline import Pipeline, Result, Success, Failure\nfrom core.pipeline import validate_not_empty, parse_json, validate_schema, transform_keys_to_lower\n\ndef test_success_map():\n    result = Success(5).map(lambda x: x * 2)\n    assert result.unwrap() == 10\n\ndef test_failure_map():\n    result = Failure(\"error\").map(lambda x: x * 2)\n    assert result.unwrap_or(0) == 0\n\ndef test_success_bind():\n    result = Success(5).bind(lambda x: Success(x * 2))\n    assert result.unwrap() == 10\n\ndef test_validate_not_empty():\n    assert validate_not_empty(\"hello\").unwrap() == \"hello\"\n    assert validate_not_empty(\"\").unwrap_or(None) is None\n\ndef test_parse_json_valid():\n    result = parse_json('{\"name\": \"test\"}')\n    assert result.unwrap() == {\"name\": \"test\"}\n\ndef test_pipeline_success():\n    p = Pipeline()\n    p.add_stage(\"validate\", validate_not_empty)\n    p.add_stage(\"parse\", parse_json)\n    result = p.run('{\"key\": \"value\"}')\n    assert result.unwrap() == {\"key\": \"value\"}\n\ndef test_pipeline_stops_on_failure():\n    p = Pipeline()\n    p.add_stage(\"validate\", validate_not_empty)\n    p.add_stage(\"parse\", parse_json)\n    result = p.run('')\n    assert result.unwrap_or(None) is None\n",
  "hidden_test_file": "import pytest\nimport sys\nsys.path.insert(0, 'src')\nfrom core.pipeline import Pipeline, Result, Success, Failure\nfrom core.pipeline import validate_not_empty, parse_json, validate_schema, transform_keys_to_lower\n\ndef test_failure_bind_short_circuits():\n    called = []\n    def track(x):\n        called.append(x)\n        return Success(x)\n    result = Failure(\"err\").bind(track)\n    assert len(called) == 0\n\ndef test_parse_json_invalid():\n    result = parse_json('not json')\n    assert result.unwrap_or(None) is None\n\ndef test_validate_schema_missing_field():\n    result = validate_schema({\"name\": \"test\"}, [\"name\", \"email\"])\n    assert result.unwrap_or(None) is None\n\ndef test_validate_schema_success():\n    result = validate_schema({\"name\": \"test\", \"email\": \"a@b.com\"}, [\"name\", \"email\"])\n    assert result.unwrap() == {\"name\": \"test\", \"email\": \"a@b.com\"}\n\ndef test_transform_keys():\n    result = transform_keys_to_lower({\"Name\": \"test\", \"EMAIL\": \"a@b.com\"})\n    data = result.unwrap()\n    assert \"name\" in data\n    assert \"email\" in data\n\ndef test_pipeline_run_all_collects_errors():\n    def always_fail(x):\n        return Failure(\"stage failed\")\n    p = Pipeline()\n    p.add_stage(\"fail1\", always_fail)\n    p.add_stage(\"fail2\", always_fail)\n    result, errors = p.run_all(\"data\")\n    assert len(errors) >= 1\n\ndef test_complex_pipeline():\n    p = Pipeline()\n    p.add_stage(\"validate\", validate_not_empty)\n    p.add_stage(\"parse\", parse_json)\n    p.add_stage(\"schema\", lambda d: validate_schema(d, [\"name\"]))\n    p.add_stage(\"transform\", transform_keys_to_lower)\n    result = p.run('{\"Name\": \"Test\"}')\n    data = result.unwrap()\n    assert data == {\"name\": \"Test\"}\n\ndef test_unwrap_raises_on_failure():\n    with pytest.raises(Exception):\n        Failure(\"error\").unwrap()\n\ndef test_nested_bind():\n    result = (\n        Success(\"hello\")\n        .bind(lambda x: Success(x.upper()))\n        .bind(lambda x: Success(x + \"!\"))\n    )\n    assert result.unwrap() == \"HELLO!\"\n",
  "expected_files": ["src/core/pipeline.py"],
  "tags": ["result-type", "pipeline", "error-handling", "functional"],
  "difficulty": "hard"
}
