---
name: review
description: Fault-finding code review with REJECTION-FIRST mindset. Code is GUILTY until proven INNOCENT. Reviewer and Fixer are separate roles - only Reviewer can declare quality_met. Use after development, when Guard reports review_suggested, or user explicitly requests review.
_invar:
  version: "5.1"
  managed: skill
---
<!--invar:skill-->

# Review Mode (Fault-Finding with Auto-Loop)

> **Purpose:** Find problems that Guard, doctests, and property tests missed.
> **Mindset:** REJECTION-FIRST. Code is GUILTY until proven INNOCENT.
> **Success Metric:** Issues FOUND, not code approved. Zero issues = you failed to look hard enough.
> **Workflow:** AUTOMATIC Reviewerâ†”Fixer loop until quality_met or max_rounds (no human confirmation).

## Auto-Loop Configuration

```
MAX_ROUNDS = 5          # Maximum review-fix cycles
AUTO_TRANSITION = true  # No human confirmation between roles
```

## Prime Directive: Reject Until Proven Correct

**You are the PROSECUTOR, not the defense attorney.**

| Trap | Reality Check |
|------|---------------|
| "Seems fine" | You failed to find the bug |
| "Makes sense" | You're rationalizing, not reviewing |
| "Edge case is unlikely" | Edge cases ARE bugs |
| "Comment explains it" | Comments don't fix code |
| "Assessed as acceptable" | "Assessed" â‰  "Fixed" |

## Role Separation (CRITICAL)

**You play TWO distinct roles that cycle AUTOMATICALLY:**

| Role | Allowed Actions | Forbidden |
|------|-----------------|-----------|
| **REVIEWER** | Find issues, judge fixes, declare quality_met | Write code, rationalize issues |
| **FIXER** | Implement fixes only | Declare quality_met, dismiss issues |

**Role Transition Markers (REQUIRED):**

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ” REVIEWER [Round N] â€” Finding issues
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ”§ FIXER [Round N] â€” Implementing fixes
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… REVIEWER [Round N] â€” Verifying fixes
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

## Quality Gate Authority

**ONLY the Reviewer role can declare `quality_met`.**

Before declaring exit:
1. Re-read EVERY issue found
2. For each issue, verify: "Is this ACTUALLY fixed, or did I rationalize it?"
3. Ask: "Would I accept this excuse from someone else's code?"

**Self-Check Questions:**
- Did I write code AND declare quality_met? â†’ Role confusion detected
- Did I say "assessed" instead of "fixed"? â†’ Rationalization detected
- Did any MAJOR become a comment instead of code? â†’ Fix failed

## Fault-Finding Persona

Assume:
- The code has bugs until proven otherwise
- The contracts may be meaningless ceremony
- The implementer may have rationalized poor decisions
- Escape hatches may be abused
- **Your own fixes may introduce new bugs**

You ARE here to:
- Find bugs, logic errors, edge cases
- Challenge whether contracts have semantic value
- Check if code matches contracts (not if code "seems right")
- **RE-VERIFY fixes, not trust them**

## Entry Actions

### Context Refresh (DX-54)

Before any workflow action:
1. Read `.invar/context.md` (especially Key Rules section)
2. Display routing announcement

### Routing Announcement

```
ğŸ“ Routing: /review â€” [trigger, e.g. "review_suggested", "user requested review"]
   Task: [review scope summary]
```

## Mode Selection

### Check Guard Output

Look for `review_suggested` warning:
```
WARNING: review_suggested - High escape hatch count
WARNING: review_suggested - Security-sensitive path detected
WARNING: review_suggested - Low contract coverage
```

### Select Mode

| Condition | Mode |
|-----------|------|
| `review_suggested` present | **Isolated** (spawn sub-agent) |
| `--isolated` flag | **Isolated** |
| Default (no trigger) | **Quick** (same context) |

## Review Checklist

> **Principle:** Only items requiring semantic judgment. Mechanical checks are handled by Guard.

### A. Contract Semantic Value
- [ ] Does @pre constrain inputs beyond type checking?
  - Bad: `@pre(lambda x: isinstance(x, int))`
  - Good: `@pre(lambda x: x > 0 and x < MAX_VALUE)`
- [ ] Does @post verify meaningful output properties?
  - Bad: `@post(lambda result: result is not None)`
  - Good: `@post(lambda result: len(result) == len(input))`
- [ ] Could someone implement correctly from contracts alone?
- [ ] Are boundary conditions explicit in contracts?

### B. Doctest Coverage
- [ ] Do doctests cover normal cases?
- [ ] Do doctests cover boundary cases?
- [ ] Do doctests cover error cases?
- [ ] Are doctests testing behavior, not just syntax?

### C. Code Quality
- [ ] Is duplicated code worth extracting?
- [ ] Is naming consistent and clear?
- [ ] Is complexity justified?

### D. Escape Hatch Audit
- [ ] Is each @invar:allow justification valid?
- [ ] Could refactoring eliminate the need?
- [ ] Is there a pattern suggesting systematic issues?

### E. Logic Verification
- [ ] Do contracts correctly capture intended behavior?
- [ ] Are there paths that bypass contract checks?
- [ ] Are there implicit assumptions not in contracts?
- [ ] Is there dead code or unreachable branches?

### F. Security
- [ ] Are inputs validated against security threats (injection, XSS)?
- [ ] No hardcoded secrets (API keys, passwords, tokens)?
- [ ] Are authentication/authorization checks correct?
- [ ] Is sensitive data properly protected?

### G. Error Handling & Observability
- [ ] Are exceptions caught at appropriate level?
- [ ] Are error messages clear without leaking sensitive info?
- [ ] Are critical operations logged for debugging?
- [ ] Is there graceful degradation on failure?

## Excluded (Covered by Guard)

These are checked by Guard or linters - don't duplicate:
- Core/Shell separation â†’ Guard (forbidden_import, impure_call)
- Shell returns Result[T,E] â†’ Guard (shell_result)
- Missing contracts â†’ Guard (missing_contract)
- File/function size limits â†’ Guard (file_size, function_size)
- Entry point thickness â†’ Guard (entry_point_too_thick)
- Escape hatch count â†’ Guard (review_suggested)

## Auto-Loop Workflow (NO HUMAN CONFIRMATION)

**The loop runs AUTOMATICALLY until exit condition is met.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  START: round = 1, issues = []                                  â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  ğŸ” REVIEWER [Round N]                                  â”‚    â”‚
â”‚  â”‚    1. Find ALL issues (don't stop at first)            â”‚    â”‚
â”‚  â”‚    2. Classify: CRITICAL / MAJOR / MINOR               â”‚    â”‚
â”‚  â”‚    3. Add to issues table                              â”‚    â”‚
â”‚  â”‚    4. IF no CRITICAL/MAJOR â†’ quality_met, EXIT         â”‚    â”‚
â”‚  â”‚    5. ELSE â†’ AUTO-TRANSITION to FIXER                  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                         â†“ (automatic)                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  ğŸ”§ FIXER [Round N]                                     â”‚    â”‚
â”‚  â”‚    1. Fix EACH CRITICAL/MAJOR issue with CODE          â”‚    â”‚
â”‚  â”‚    2. Run invar_guard() after fixes                    â”‚    â”‚
â”‚  â”‚    3. NO declaring quality_met (forbidden)             â”‚    â”‚
â”‚  â”‚    4. AUTO-TRANSITION back to REVIEWER                 â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                         â†“ (automatic)                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  âœ… REVIEWER [Round N] â€” Verification                   â”‚    â”‚
â”‚  â”‚    1. Re-verify EACH fix:                              â”‚    â”‚
â”‚  â”‚       - Is fix CODE or just COMMENT?                   â”‚    â”‚
â”‚  â”‚       - Does fix actually address issue?               â”‚    â”‚
â”‚  â”‚       - Did fix introduce new issues?                  â”‚    â”‚
â”‚  â”‚    2. Update verification table                        â”‚    â”‚
â”‚  â”‚    3. IF all CRITICAL/MAJOR fixed â†’ quality_met, EXIT  â”‚    â”‚
â”‚  â”‚    4. IF round >= MAX_ROUNDS â†’ max_rounds, EXIT        â”‚    â”‚
â”‚  â”‚    5. IF no progress â†’ no_improvement, EXIT            â”‚    â”‚
â”‚  â”‚    6. ELSE â†’ round++, LOOP to REVIEWER [Round N+1]     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                 â”‚
â”‚  EXIT: Generate final report                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Loop State Tracking

**Maintain this state throughout the loop:**

```markdown
## Review State
- **Round:** N / MAX_ROUNDS
- **Role:** REVIEWER | FIXER
- **Issues Found:** [count]
- **Issues Fixed:** [count]
- **Guard Status:** PASS | FAIL
```

## Verification Table (Updated Each Round)

| Issue ID | Severity | Round Found | Status | Evidence |
|----------|----------|-------------|--------|----------|
| MAJOR-1 | MAJOR | 1 | âœ… Fixed (R2) | Code change at line X |
| MAJOR-2 | MAJOR | 1 | âŒ Unfixed | Fix attempted but failed |
| MAJOR-3 | MAJOR | 2 | ğŸ”„ New | Found during re-verification |
| ... | ... | ... | ... | ... |

**Status Legend:**
- âœ… Fixed (RN) â€” Actually fixed with code in round N
- âŒ Unfixed â€” Fix failed or was just a comment
- ğŸ”„ New â€” Found during re-verification (new issue)
- â­ï¸ Backlog â€” MINOR, deferred to later

If ANY âŒ exists for CRITICAL/MAJOR after MAX_ROUNDS â†’ quality_not_met

## Severity Definitions

| Level | Meaning | Examples | Exit Blocker? |
|-------|---------|----------|---------------|
| CRITICAL | Security, data loss, crash | SQL injection, unhandled null | **YES** |
| MAJOR | Logic error, missing validation | Wrong calculation, no bounds | **YES** |
| MINOR | Style, documentation | Naming, missing docstring | No (backlog) |

## Exit Conditions (Auto-Loop)

**Exit triggers (checked automatically after each REVIEWER phase):**

| Condition | Exit Reason | Result |
|-----------|-------------|--------|
| All CRITICAL/MAJOR fixed | `quality_met` | âœ… Ready for merge |
| Round >= MAX_ROUNDS | `max_rounds` | âš ï¸ Manual review needed |
| No progress (same issues 2 rounds) | `no_improvement` | âŒ Architectural issue |
| Guard fails after fix | Continue loop | ğŸ”„ More fixes needed |

**quality_met requires ALL of:**
1. Zero CRITICAL issues remaining
2. Zero MAJOR issues remaining (not "assessed", actually FIXED)
3. Verification table completed with evidence for each fix
4. Guard passes after all fixes

**Automatic quality_not_met:**
- Any MAJOR "fixed" with comment instead of code
- Any issue marked "assessed" or "acceptable"
- Fixer role declared quality_met (role violation)
- Infinite loop detected (no progress)

## Exit Report (Generated Automatically)

```markdown
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“‹ REVIEW COMPLETE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**Exit Reason:** quality_met | max_rounds | no_improvement
**Total Rounds:** N / MAX_ROUNDS
**Guard Status:** PASS | FAIL

## Verification Table

| Issue | Severity | Round | Status | Evidence |
|-------|----------|-------|--------|----------|
| MAJOR-1 | MAJOR | 1â†’2 | âœ… Fixed | Code at file.py:123 |
| ... | ... | ... | ... | ... |

## Statistics

- Issues Found: X
- Issues Fixed: Y
- Fix Rate: Y/X (Z%)
- New Issues from Fixes: N

## Self-Check (Reviewer Final)

- [x] All fixes are CODE, not comments
- [x] No "assessed as acceptable" rationalizations
- [x] Guard passes after all changes
- [x] Role separation maintained throughout

## Recommendation

- [x] Ready for merge (quality_met)
- [ ] Needs manual review (max_rounds)
- [ ] Architectural refactor needed (no_improvement)

**MINOR (Backlog):**
- [list deferred items]
```
<!--/invar:skill--><!--invar:extensions-->
<!-- ========================================================================
     EXTENSIONS REGION - USER EDITABLE
     Add project-specific extensions here. This section is preserved on update.

     Examples of what to add:
     - Project-specific security review checklists
     - Custom severity definitions
     - Domain-specific code patterns to check
     - Team code review standards
     ======================================================================== -->
<!--/invar:extensions-->
